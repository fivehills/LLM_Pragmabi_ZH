#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tabåˆ†éš”å§”å©‰è¯­è¯„ä¼°å™¨
ä¸“é—¨å¤„ç†Tabåˆ†éš”çš„å§”å©‰è¯­å­¦æœ¯æ•°æ®é›†
"""

import json
import pandas as pd
import numpy as np
import requests
import time
import random
from datetime import datetime
from typing import List, Dict, Any, Optional

class TabEuphemismEvaluator:
    def __init__(self, tsv_data_path: str, openrouter_api_key: str):
        """
        åˆå§‹åŒ–Tabåˆ†éš”å§”å©‰è¯­è¯„ä¼°å™¨
        
        Args:
            tsv_data_path: TSVæ•°æ®æ–‡ä»¶è·¯å¾„
            openrouter_api_key: OpenRouter APIå¯†é’¥
        """
        self.tsv_data_path = tsv_data_path
        self.api_key = _api_key
        self.base_url = "..." ### your API url
        
        self.raw_data = None
        self.test_data = None
        self.results = {}
        
        # è¯„ä¼°æ¨¡å‹é…ç½®ï¼ˆå¤ç”¨æˆåŠŸé…ç½®ï¼‰
        self.models = {
            'qwen-72b': {
                'name': 'Qwen 72B',
                'model_id': 'qwen/qwen-2.5-72b-instruct',
                'role': 'primary_validator',
                'type': 'ä¸­æ–‡æ¨¡å‹'
            },
            'gemini-2.5-flash': {
                'name': 'Gemini 2.5 Flash',
                'model_id': 'google/gemini-2.5-flash',
                'role': 'primary_validator', 
                'type': 'å›½é™…æ¨¡å‹'
            },
            'deepseek-chat': {
                'name': 'DeepSeek Chat',
                'model_id': 'deepseek/deepseek-chat',
                'role': 'arbitrator',
                'type': 'ä¸­æ–‡æ¨¡å‹'
            }
        }
    
    def load_euphemism_data(self):
        """åŠ è½½å§”å©‰è¯­æ•°æ®"""
        try:
            # è¯»å–Tabåˆ†éš”çš„æ–‡ä»¶
            self.raw_data = pd.read_csv(
                self.tsv_data_path, 
                sep='\t', 
                encoding='utf-8',
                quoting=3  # QUOTE_NONEï¼Œé¿å…å¼•å·é—®é¢˜
            )
            
            print(f"âœ… æˆåŠŸåŠ è½½å§”å©‰è¯­æ•°æ®: {len(self.raw_data)} æ¡")
            
            # æ˜¾ç¤ºæ•°æ®ç»“æ„
            print(f"ğŸ“‹ æ•°æ®åˆ—: {list(self.raw_data.columns)}")
            
            # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['EUPHEMISM', 'EXAMPLE OF USAGE', 'MEANING IN CHINESE']
            missing_columns = [col for col in required_columns if col not in self.raw_data.columns]
            
            if missing_columns:
                print(f"âš ï¸ ç¼ºå¤±å…³é”®åˆ—: {missing_columns}")
                return False
            
            # ç»Ÿè®¡ç›®æ ‡é¢†åŸŸåˆ†å¸ƒ
            if 'TARGET DOMAIN' in self.raw_data.columns:
                domain_counts = self.raw_data['TARGET DOMAIN'].value_counts()
                print(f"\nğŸ“Š ç›®æ ‡é¢†åŸŸåˆ†å¸ƒ:")
                for domain, count in domain_counts.head(10).items():
                    print(f"   {domain}: {count} æ¡")
            
            # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
            print(f"\nğŸ“‹ æ•°æ®æ ·æœ¬:")
            for i in range(min(3, len(self.raw_data))):
                euphemism = self.raw_data.iloc[i]['EUPHEMISM']
                meaning = self.raw_data.iloc[i]['MEANING IN CHINESE']
                example = self.raw_data.iloc[i]['EXAMPLE OF USAGE'][:50] + "..."
                print(f"   {i+1}. {euphemism} â†’ {meaning}")
                print(f"      ä¾‹å¥: {example}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
    
    def create_evaluation_tasks(self, sample_size: int = 100):
        """åˆ›å»ºè¯„ä¼°ä»»åŠ¡"""
        if self.raw_data is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return False
        
        print(f"ğŸ¯ åˆ›å»ºå§”å©‰è¯­ç†è§£è¯„ä¼°ä»»åŠ¡")
        print("="*50)
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        self.test_data = self._prepare_test_samples(sample_size)
        
        # ä»»åŠ¡1: å§”å©‰è¯­è¯†åˆ«ä»»åŠ¡
        self.evaluation_tasks = {
            'euphemism_identification': {
                'name': 'å§”å©‰è¯­è¯†åˆ«',
                'description': 'åˆ¤æ–­å¥å­ä¸­æ˜¯å¦ä½¿ç”¨äº†å§”å©‰è¯­',
                'prompt_template': self._create_identification_prompt(),
                'scoring_method': 'binary_classification'
            },
            
            'euphemism_explanation': {
                'name': 'å§”å©‰è¯­å«ä¹‰è§£é‡Š',
                'description': 'è§£é‡Šå§”å©‰è¯­çš„çœŸå®å«ä¹‰',
                'prompt_template': self._create_explanation_prompt(),
                'scoring_method': 'semantic_matching'
            }
        }
        
        print(f"âœ… åˆ›å»ºäº† {len(self.evaluation_tasks)} ä¸ªè¯„ä¼°ä»»åŠ¡")
        print(f"ğŸ“Š å‡†å¤‡äº† {len(self.test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
        
        return True
    
    def _prepare_test_samples(self, sample_size: int):
        """å‡†å¤‡æµ‹è¯•æ ·æœ¬"""
        print(f"ğŸ“‹ å‡†å¤‡æµ‹è¯•æ ·æœ¬...")
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_data = self.raw_data.dropna(subset=['EUPHEMISM', 'EXAMPLE OF USAGE', 'MEANING IN CHINESE'])
        
        # éšæœºæŠ½æ ·
        if len(valid_data) > sample_size:
            test_samples = valid_data.sample(sample_size, random_state=42)
        else:
            test_samples = valid_data
        
        # è½¬æ¢ä¸ºè¯„ä¼°æ ¼å¼
        test_data = []
        for idx, row in test_samples.iterrows():
            # åˆ›å»ºæ­£ä¾‹ï¼ˆåŒ…å«å§”å©‰è¯­çš„å¥å­ï¼‰
            positive_sample = {
                'id': f"{row['ID']}_positive",
                'text': row['EXAMPLE OF USAGE'],
                'euphemism_word': row['EUPHEMISM'],
                'true_meaning': row['MEANING IN CHINESE'],
                'target_domain': row.get('TARGET DOMAIN', 'Unknown'),
                'has_euphemism': True,
                'expected_answer': 'A'  # Aè¡¨ç¤ºæœ‰å§”å©‰è¯­
            }
            test_data.append(positive_sample)
            
            # åˆ›å»ºè´Ÿä¾‹ï¼ˆå°†å§”å©‰è¯­æ›¿æ¢ä¸ºç›´æ¥è¡¨è¾¾ï¼‰
            direct_text = self._create_direct_expression(row['EXAMPLE OF USAGE'], row['EUPHEMISM'], row['MEANING IN CHINESE'])
            if direct_text:
                negative_sample = {
                    'id': f"{row['ID']}_negative",
                    'text': direct_text,
                    'euphemism_word': '',
                    'true_meaning': row['MEANING IN CHINESE'],
                    'target_domain': row.get('TARGET DOMAIN', 'Unknown'),
                    'has_euphemism': False,
                    'expected_answer': 'B'  # Bè¡¨ç¤ºæ²¡æœ‰å§”å©‰è¯­
                }
                test_data.append(negative_sample)
        
        print(f"âœ… å‡†å¤‡äº† {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬ (æ­£ä¾‹: {len([s for s in test_data if s['has_euphemism']])}, è´Ÿä¾‹: {len([s for s in test_data if not s['has_euphemism']])})")
        
        return test_data
    
    def _create_direct_expression(self, original_text, euphemism, meaning):
        """åˆ›å»ºç›´æ¥è¡¨è¾¾çš„å¯¹ç…§å¥å­"""
        # ç®€å•æ›¿æ¢ç­–ç•¥
        if euphemism in original_text:
            # æå–meaningä¸­çš„æ ¸å¿ƒè¯æ±‡
            meaning_clean = meaning.replace('[', '').replace(']', '').replace('å¤šç”¨äºæ­»è€…çš„æ‚¼æ…°', '')
            direct_words = meaning_clean.split('ï¼Œ')[0].split('ã€')[0].strip()
            
            # æ›¿æ¢å§”å©‰è¯­ä¸ºç›´æ¥è¡¨è¾¾
            direct_text = original_text.replace(euphemism, direct_words)
            return direct_text
        
        return None
    
    def _create_identification_prompt(self):
        """åˆ›å»ºå§”å©‰è¯­è¯†åˆ«prompt"""
        return '''ä½œä¸ºä¸­æ–‡è¯­è¨€ä¸“å®¶ï¼Œè¯·åˆ¤æ–­ä»¥ä¸‹å¥å­ä¸­æ˜¯å¦ä½¿ç”¨äº†å§”å©‰è¯­è¡¨è¾¾ï¼š

å¥å­ï¼š"{text}"

## å§”å©‰è¯­å®šä¹‰ï¼š
å§”å©‰è¯­æ˜¯ç”¨é—´æ¥ã€æ¸©å’Œçš„æ–¹å¼è¡¨è¾¾æ•æ„Ÿã€ä¸æ„‰å¿«æˆ–ç¦å¿Œå†…å®¹çš„è¯­è¨€ç°è±¡ã€‚

## åˆ¤æ–­è¦ç‚¹ï¼š
â€¢ å§”å©‰è¯­ï¼šé¿å…ç›´æ¥è¡¨è¾¾ï¼Œä½¿ç”¨éšå–»ã€è½¬å–»ç­‰ä¿®è¾æ‰‹æ³•
â€¢ ç›´æ¥è¡¨è¾¾ï¼šç›´ç™½åœ°è¡¨è¾¾æ„æ€ï¼Œä¸åšä¿®é¥°æˆ–å›é¿

## å§”å©‰è¯­å‚è€ƒä¾‹å­ï¼š

### å§”å©‰è¯­ä¾‹å­ï¼ˆé€‰æ‹©Aï¼‰ï¼š
1. "ä»–å·²ç»å®‰æ¯äº†" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆéšå–»ï¼šæ­»äº¡å¦‚ç¡çœ ï¼‰
2. "å¥¹ç»ˆäºé™é™åœ°å®‰çœ " â†’ å§”å©‰è¡¨è¾¾æ­»äº¡
3. "èµ°å®Œäº†äººç”Ÿå†ç¨‹" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆéšå–»ï¼šç”Ÿå‘½å¦‚æ—…ç¨‹ï¼‰
4. "ç™¾å¹´ä¹‹å" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆç”¨é•¿å¯¿åè¯´æ­»äº¡ï¼‰
5. "èƒŒä¸–" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆéšå–»ï¼šæ­»äº¡å¦‚ç¦»å¼€ï¼‰
6. "é—­çœ¼" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆè½¬å–»ï¼šç”¨æ­»äº¡ç‰¹å¾ä»£æ›¿æ­»äº¡ï¼‰
7. "æ¯•å‘½" â†’ å§”å©‰è¡¨è¾¾æ­»äº¡ï¼ˆéšå–»ï¼šç”Ÿå‘½å¦‚ä»»åŠ¡å®Œæˆï¼‰

### ç›´æ¥è¡¨è¾¾ä¾‹å­ï¼ˆé€‰æ‹©Bï¼‰ï¼š
1. "ä»–æ˜¨å¤©å»ä¸–äº†" â†’ ç›´æ¥è¡¨è¾¾æ­»äº¡
2. "å¥¹æ­»äº†" â†’ ç›´æ¥è¡¨è¾¾æ­»äº¡
3. "ä»–ç»“æŸäº†ç”Ÿå‘½" â†’ ç›´æ¥è¡¨è¾¾æ­»äº¡
4. "å¾ˆå¤šå¹´ä»¥å" â†’ ç›´æ¥è¡¨è¾¾æ—¶é—´
5. "ç¦»å¼€äº†äººä¸–" â†’ ç›¸å¯¹ç›´æ¥çš„è¡¨è¾¾
6. "ä»–é—­ä¸Šäº†çœ¼ç›" â†’ å¦‚æœæŒ‡ç¡è§‰ï¼Œåˆ™æ˜¯ç›´æ¥è¡¨è¾¾
7. "å®Œæˆäº†ä»»åŠ¡" â†’ å¦‚æœæŒ‡å·¥ä½œï¼Œåˆ™æ˜¯ç›´æ¥è¡¨è¾¾

è¯·é€‰æ‹©ï¼š
A. å¥å­ä¸­ä½¿ç”¨äº†å§”å©‰è¯­
B. å¥å­ä¸­æ²¡æœ‰ä½¿ç”¨å§”å©‰è¯­

åªéœ€å›ç­”Aæˆ–Bï¼š'''
    
    def _create_explanation_prompt(self):
        """åˆ›å»ºå§”å©‰è¯­è§£é‡Šprompt"""
        return '''ä½œä¸ºä¸­æ–‡è¯­è¨€ä¸“å®¶ï¼Œè¯·è§£é‡Šä»¥ä¸‹å¥å­ä¸­å§”å©‰è¯­çš„çœŸå®å«ä¹‰ï¼š

å¥å­ï¼š"{text}"
å§”å©‰è¯­ï¼š"{euphemism_word}"

è¯·ç”¨ç®€æ´æ˜ç¡®çš„è¯­è¨€è§£é‡Šè¿™ä¸ªå§”å©‰è¯­çš„çœŸå®å«ä¹‰ã€‚

## è§£é‡Šè¦æ±‚ï¼š
â€¢ ç”¨ç›´ç™½çš„è¯­è¨€è¯´æ˜çœŸå®å«ä¹‰
â€¢ ä¸è¶…è¿‡10ä¸ªå­—
â€¢ é¿å…å†æ¬¡ä½¿ç”¨å§”å©‰è¯­

## è§£é‡Šç¤ºä¾‹ï¼š
å§”å©‰è¯­ï¼š"å®‰æ¯" â†’ çœŸå®å«ä¹‰ï¼š"æ­»äº¡"
å§”å©‰è¯­ï¼š"å®‰çœ " â†’ çœŸå®å«ä¹‰ï¼š"æ­»äº¡"
å§”å©‰è¯­ï¼š"ç™¾å¹´" â†’ çœŸå®å«ä¹‰ï¼š"æ­»äº¡"
å§”å©‰è¯­ï¼š"èƒŒä¸–" â†’ çœŸå®å«ä¹‰ï¼š"æ­»äº¡"
å§”å©‰è¯­ï¼š"é—­çœ¼" â†’ çœŸå®å«ä¹‰ï¼š"æ­»äº¡"

è¯·ç›´æ¥ç»™å‡ºçœŸå®å«ä¹‰ï¼ˆä¸è¶…è¿‡10ä¸ªå­—ï¼‰ï¼š'''
    
    def call_model(self, model_key: str, prompt: str, max_retries: int = 3) -> Optional[str]:
        """è°ƒç”¨æ¨¡å‹API"""
        model_config = self.models[model_key]
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/tab-euphemism-eval",
            "X-Title": "Tab Chinese Euphemism Evaluation"
        }
        
        data = {
            "model": model_config['model_id'],
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 100,
            "temperature": 0.1
        }
        
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    self.base_url,
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content'].strip()
                elif response.status_code == 429:
                    wait_time = 2 ** attempt
                    print(f"      â³ APIé™æµï¼Œç­‰å¾…{wait_time}ç§’...")
                    time.sleep(wait_time)
                    continue
                else:
                    if attempt == max_retries - 1:
                        print(f"      âŒ APIé”™è¯¯ {response.status_code}")
                        return None
                    time.sleep(1)
            
            except requests.RequestException as e:
                if attempt == max_retries - 1:
                    print(f"      âš ï¸ è¯·æ±‚å¼‚å¸¸: {e}")
                    return None
                time.sleep(2)
        
        return None
    
    def parse_response(self, response: str, task_type: str) -> str:
        """è§£ææ¨¡å‹å“åº”"""
        if not response:
            return "ERROR"
        
        response = response.strip()
        
        if task_type == 'euphemism_identification':
            # æŸ¥æ‰¾Aæˆ–Bé€‰é¡¹
            if response.upper().startswith('A') or 'ç­”æ¡ˆï¼šA' in response:
                return 'A'
            elif response.upper().startswith('B') or 'ç­”æ¡ˆï¼šB' in response:
                return 'B'
            
            # æŸ¥æ‰¾å…³é”®è¯
            if 'å§”å©‰è¯­' in response or 'ä½¿ç”¨äº†' in response:
                return 'A'
            elif 'æ²¡æœ‰' in response or 'ä¸æ˜¯' in response:
                return 'B'
        
        elif task_type == 'euphemism_explanation':
            # å¯¹äºè§£é‡Šä»»åŠ¡ï¼Œè¿”å›æ¸…ç†åçš„å“åº”
            # ç§»é™¤å¸¸è§çš„å‰ç¼€
            cleaned = response.replace('çœŸå®å«ä¹‰ï¼š', '').replace('å«ä¹‰ï¼š', '').replace('æ„æ€ï¼š', '')
            return cleaned.strip()
        
        return "UNCLEAR"
    
    def run_evaluation(self, task_name: str, max_samples: Optional[int] = None):
        """è¿è¡Œè¯„ä¼°ä»»åŠ¡ï¼ˆä½¿ç”¨åŒé‡éªŒè¯+ä»²è£ï¼‰"""
        if not self.test_data or task_name not in self.evaluation_tasks:
            print(f"âŒ ä»»åŠ¡ {task_name} ä¸å­˜åœ¨æˆ–æ•°æ®æœªå‡†å¤‡")
            return False
        
        task_info = self.evaluation_tasks[task_name]
        test_samples = self.test_data[:max_samples] if max_samples else self.test_data
        
        print(f"\nğŸš€ å¼€å§‹è¯„ä¼°: {task_info['name']}")
        print(f"ğŸ“Š æµ‹è¯•æ ·æœ¬: {len(test_samples)} æ¡")
        print("="*60)
        
        results = []
        agreement_count = 0
        arbitration_count = 0
        
        for i, sample in enumerate(test_samples):
            print(f"\nğŸ“ æ ·æœ¬ {i+1}/{len(test_samples)}")
            print(f"   ç±»å‹: {'å§”å©‰è¯­å¥å­' if sample['has_euphemism'] else 'ç›´æ¥è¡¨è¾¾'}")
            print(f"   æ–‡æœ¬: {sample['text'][:60]}...")
            
            # æ„å»ºprompt
            if task_name == 'euphemism_identification':
                prompt = task_info['prompt_template'].format(text=sample['text'])
            else:
                prompt = task_info['prompt_template'].format(
                    text=sample['text'],
                    euphemism_word=sample['euphemism_word']
                )
            
            # åŒé‡éªŒè¯
            print(f"   ğŸ‡¨ğŸ‡³ Qwen 72B: ", end="")
            qwen_response = self.call_model('qwen-72b', prompt)
            qwen_prediction = self.parse_response(qwen_response, task_name) if qwen_response else "ERROR"
            print(f"{qwen_prediction}")
            
            print(f"   ğŸŒ Gemini 2.5: ", end="")
            gemini_response = self.call_model('gemini-2.5-flash', prompt)
            gemini_prediction = self.parse_response(gemini_response, task_name) if gemini_response else "ERROR"
            print(f"{gemini_prediction}")
            
            # ä¸€è‡´æ€§æ£€æŸ¥å’Œä»²è£
            final_prediction = None
            arbitration_used = False
            
            if qwen_prediction == gemini_prediction and qwen_prediction not in ["ERROR", "UNCLEAR"]:
                final_prediction = qwen_prediction
                agreement_count += 1
                print(f"   âœ… ä¸€è‡´é¢„æµ‹: {final_prediction}")
            else:
                print(f"   âš–ï¸  éœ€è¦ä»²è£...")
                deepseek_response = self.call_model('deepseek-chat', prompt)
                final_prediction = self.parse_response(deepseek_response, task_name) if deepseek_response else "ERROR"
                arbitration_used = True
                arbitration_count += 1
                print(f"   ğŸ” ä»²è£ç»“æœ: {final_prediction}")
            
            # è¯„ä¼°å‡†ç¡®æ€§ï¼ˆä»…å¯¹è¯†åˆ«ä»»åŠ¡ï¼‰
            is_correct = None
            if task_name == 'euphemism_identification' and final_prediction in ['A', 'B']:
                is_correct = final_prediction == sample['expected_answer']
                status = "âœ…" if is_correct else "âŒ"
                print(f"   {status} é¢„æµ‹: {final_prediction}, æœŸæœ›: {sample['expected_answer']}")
            
            # è®°å½•ç»“æœ
            result = {
                'sample_id': sample['id'],
                'text': sample['text'],
                'has_euphemism': sample['has_euphemism'],
                'euphemism_word': sample['euphemism_word'],
                'true_meaning': sample['true_meaning'],
                'qwen_prediction': qwen_prediction,
                'gemini_prediction': gemini_prediction,
                'final_prediction': final_prediction,
                'expected_answer': sample.get('expected_answer'),
                'correct': is_correct,
                'arbitration_used': arbitration_used,
                'target_domain': sample['target_domain']
            }
            
            results.append(result)
            time.sleep(1)  # APIè°ƒç”¨é—´éš”
        
        # ä¿å­˜ç»“æœ
        self.results[task_name] = {
            'task_info': task_info,
            'results': results,
            'statistics': {
                'total_samples': len(results),
                'agreement_rate': agreement_count / len(results),
                'arbitration_rate': arbitration_count / len(results)
            }
        }
        
        # æ˜¾ç¤ºç»Ÿè®¡
        self._print_task_statistics(task_name)
        
        return True
    
    def _print_task_statistics(self, task_name: str):
        """æ‰“å°ä»»åŠ¡ç»Ÿè®¡"""
        if task_name not in self.results:
            return
        
        task_results = self.results[task_name]
        results = task_results['results']
        stats = task_results['statistics']
        
        print(f"\nğŸ“Š {task_results['task_info']['name']} ç»Ÿè®¡ç»“æœ")
        print("="*50)
        
        print(f"ğŸ“‹ åŸºç¡€ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"   æ¨¡å‹ä¸€è‡´ç‡: {stats['agreement_rate']:.2%}")
        print(f"   ä»²è£ä½¿ç”¨ç‡: {stats['arbitration_rate']:.2%}")
        
        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆä»…å¯¹è¯†åˆ«ä»»åŠ¡ï¼‰
        if task_name == 'euphemism_identification':
            valid_results = [r for r in results if r['correct'] is not None]
            if valid_results:
                correct_count = sum(1 for r in valid_results if r['correct'])
                accuracy = correct_count / len(valid_results)
                print(f"   æ•´ä½“å‡†ç¡®ç‡: {accuracy:.2%} ({correct_count}/{len(valid_results)})")
                
                # æŒ‰ç±»å‹åˆ†æ
                positive_results = [r for r in valid_results if r['has_euphemism']]
                negative_results = [r for r in valid_results if not r['has_euphemism']]
                
                if positive_results:
                    pos_correct = sum(1 for r in positive_results if r['correct'])
                    pos_accuracy = pos_correct / len(positive_results)
                    print(f"   å§”å©‰è¯­è¯†åˆ«å‡†ç¡®ç‡: {pos_accuracy:.2%} ({pos_correct}/{len(positive_results)})")
                
                if negative_results:
                    neg_correct = sum(1 for r in negative_results if r['correct'])
                    neg_accuracy = neg_correct / len(negative_results)
                    print(f"   ç›´æ¥è¡¨è¾¾è¯†åˆ«å‡†ç¡®ç‡: {neg_accuracy:.2%} ({neg_correct}/{len(negative_results)})")
    
    def export_results(self, output_dir: str = 'euphemism_evaluation_results'):
        """å¯¼å‡ºè¯„ä¼°ç»“æœ"""
        import os
        
        os.makedirs(output_dir, exist_ok=True)
        
        # å¯¼å‡ºæ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†ç»“æœ
        for task_name, task_data in self.results.items():
            task_file = os.path.join(output_dir, f'{task_name}_detailed_results.json')
            with open(task_file, 'w', encoding='utf-8') as f:
                json.dump(task_data, f, ensure_ascii=False, indent=2)
        
        # å¯¼å‡ºæ±‡æ€»æŠ¥å‘Š
        summary_report = {
            'evaluation_date': datetime.now().isoformat(),
            'data_source': self.tsv_data_path,
            'total_original_samples': len(self.raw_data) if self.raw_data is not None else 0,
            'test_samples_created': len(self.test_data) if self.test_data else 0,
            'tasks_completed': len(self.results),
            'summary_statistics': {}
        }
        
        for task_name, task_data in self.results.items():
            summary_report['summary_statistics'][task_name] = task_data['statistics']
        
        summary_file = os.path.join(output_dir, 'evaluation_summary.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è¯„ä¼°ç»“æœå·²å¯¼å‡ºåˆ°: {output_dir}/")

def main():
    print("ğŸ“ Tabåˆ†éš”ä¸­æ–‡å§”å©‰è¯­ç†è§£è¯„ä¼°ç³»ç»Ÿ")
    print("="*60)
    
    # è·å–è¾“å…¥
    tsv_path = input("è¯·è¾“å…¥Tabåˆ†éš”æ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: database.csv): ").strip()
    if not tsv_path:
        tsv_path = "zh_eupm_dataset.csv"
    
    api_key = input("è¯·è¾“å…¥ APIå¯†é’¥ (å›è½¦ä½¿ç”¨ä¹‹å‰çš„): ").strip()
    if not api_key:
        try:
            with open("config.json", "r") as f:
                config = json.load(f)
                api_key = config.get("openrouter_api_key")
                if api_key:
                    print("ğŸ”‘ ä½¿ç”¨ä¿å­˜çš„APIå¯†é’¥")
        except:
            pass
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥")
        return
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = TabEuphemismEvaluator(tsv_path, api_key)
    
    # åŠ è½½æ•°æ®
    if not evaluator.load_euphemism_data():
        return
    
    # åˆ›å»ºè¯„ä¼°ä»»åŠ¡
    sample_size = input("æµ‹è¯•æ ·æœ¬æ•°é‡ (é»˜è®¤: 50): ").strip()
    sample_size = int(sample_size) if sample_size.isdigit() else 50
    
    if not evaluator.create_evaluation_tasks(sample_size):
        return
    
    # é€‰æ‹©ä»»åŠ¡
    print(f"\nğŸ¯ å¯ç”¨è¯„ä¼°ä»»åŠ¡:")
    tasks = list(evaluator.evaluation_tasks.keys())
    for i, task in enumerate(tasks, 1):
        task_info = evaluator.evaluation_tasks[task]
        print(f"   {i}. {task_info['name']} - {task_info['description']}")
    
    task_choice = input(f"é€‰æ‹©ä»»åŠ¡ (1-{len(tasks)}, é»˜è®¤: 1): ").strip()
    try:
        selected_task = tasks[int(task_choice) - 1]
    except (ValueError, IndexError):
        selected_task = tasks[0]  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª
    
    print(f"âœ… é€‰æ‹©äº†ä»»åŠ¡: {evaluator.evaluation_tasks[selected_task]['name']}")
    
    # å¼€å§‹è¯„ä¼°
    print(f"\nğŸ’° é¢„ä¼°æˆæœ¬: ~${sample_size * 3 * 0.001:.2f}")
    confirm = input("ç¡®è®¤å¼€å§‹è¯„ä¼°å—? (y/N): ").strip().lower()
    
    if confirm == 'y':
        if evaluator.run_evaluation(selected_task):
            evaluator.export_results()
            
            print(f"\nğŸ‰ å§”å©‰è¯­è¯„ä¼°å®Œæˆ!")
            print(f"ğŸ† è¿™æ˜¯åŸºäºå­¦æœ¯æ•°æ®é›†çš„æƒå¨ä¸­æ–‡å§”å©‰è¯­ç†è§£è¯„ä¼°!")
            print(f"ğŸ“Š ä½¿ç”¨äº†åŒé‡éªŒè¯+ä»²è£çš„ä¸¥è°¨æ–¹æ³•!")
    else:
        print("è¯„ä¼°å·²å–æ¶ˆ")

if __name__ == "__main__":
    main()
